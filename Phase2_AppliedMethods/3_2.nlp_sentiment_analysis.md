# Module: NLP with spaCy & Hugging Face Transformers

---

## Extra Section: Sentiment Analysis

### Motivation
Sentiment analysis is about detecting **opinions and emotions** in text.  
It’s widely used in:
- Customer reviews (positive vs negative feedback).  
- Social media monitoring (public opinion on topics).  
- Financial markets (news sentiment for stock prediction).  

---

### Conventional Approach
Rule-based or dictionary methods (e.g., bag of words, sentiment lexicons).  
Simple but limited — often miss sarcasm, context, and subtlety.  

Example using lexicon:  
\[
\text{Sentiment Score} = \sum_{i=1}^n w_i \cdot s_i
\]  
where \( w_i \) is word frequency and \( s_i \) is sentiment polarity.

---

### Transformer-Based Approach
Modern models like **BERT** or **DistilBERT** use attention to capture **contextual meaning**.  

\[
P(\text{Positive} | x) = \text{softmax}(W \cdot h_{[CLS]} + b)
\]  

Here:
- \( h_{[CLS]} \) = contextual embedding for entire text.  
- Softmax gives probabilities for positive/negative/neutral.  

---

### Objectives
- Compare **rule-based** vs **transformer-based** sentiment analysis.  
- Apply Hugging Face pre-trained models for sentiment classification.  
- Understand trade-offs: speed vs accuracy, simple vs contextual.  

---

### Expected Outcomes
After completing this section, you will be able to:
- Run sentiment analysis on raw text.  
- Explain the difference between lexicon-based and deep learning models.  
- Apply pre-trained transformer models to real datasets.  

---

### Useful References
- [VADER Sentiment Analysis](https://github.com/cjhutto/vaderSentiment)  
- [Hugging Face Sentiment Models](https://huggingface.co/models?pipeline_tag=sentiment-analysis)  
