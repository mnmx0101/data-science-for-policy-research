{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca938b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source\n",
    "# Description\n",
    "# Retrieve\n",
    "# Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf5d8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from io import StringIO\n",
    "import difflib\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06da7835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterio\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "\n",
    "#Scipy\n",
    "from scipy.signal import medfilt2d\n",
    "\n",
    "# bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "#others\n",
    "import io\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "332a3037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ck24\\\\OneDrive - University of Illinois - Urbana\\\\Documents\\\\IPC_AID'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Home Directory\n",
    "home = 'C:\\\\Users\\\\ck24\\\\OneDrive - University of Illinois - Urbana\\\\Documents\\\\IPC_AID'\n",
    "home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d81623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AFG', 'CAF', 'COD', 'DJI', 'ETH', 'GTM', 'HTI', 'KEN', 'LBN', 'MDG', 'MOZ', 'PAK', 'SDN', 'SSD', 'YEM']\n"
     ]
    }
   ],
   "source": [
    "# IPC country list\n",
    "\n",
    "country_codes = {\n",
    "    'Afghanistan': 'AFG',\n",
    "    'Bangladesh': 'BGD',\n",
    "    'Pakistan': 'PAK',\n",
    "    'Timor-Leste': 'TLS',\n",
    "    'Burundi': 'BDI',\n",
    "    'Central African Republic': 'CAF',\n",
    "    'Congo, DRC': 'COD',  # Democratic Republic of the Congo\n",
    "    'Djibouti': 'DJI',\n",
    "    'Ethiopia': 'ETH',\n",
    "    'Kenya': 'KEN',\n",
    "    'Somalia': 'SOM',\n",
    "    'South Sudan': 'SSD',\n",
    "    'Sudan': 'SDN',\n",
    "    'Tanzania': 'TZA',\n",
    "    'Uganda': 'UGA',\n",
    "    'Angola': 'AGO',\n",
    "    'Eswatini': 'SWZ',\n",
    "    'Lesotho': 'LSO',\n",
    "    'Madagascar': 'MDG',\n",
    "    'Malawi': 'MWI',\n",
    "    'Mozambique': 'MOZ',\n",
    "    'Namibia': 'NAM',\n",
    "    'South Africa': 'ZAF',\n",
    "    'Zambia': 'ZMB',\n",
    "    'Zimbabwe': 'ZWE',\n",
    "    'Dominican Republic': 'DOM',\n",
    "    'El Salvador': 'SLV',\n",
    "    'Guatemala': 'GTM',\n",
    "    'Haiti': 'HTI',\n",
    "    'Honduras': 'HND',\n",
    "    'LAC Region (tri-National)': 'LAC',  # This is not a country, hence no ISO code\n",
    "    'Lebanon': 'LBN',\n",
    "    'Yemen': 'YEM'\n",
    "}\n",
    "\n",
    "\n",
    "country_codes = {\n",
    "    'Afghanistan': 'AFG',\n",
    "    'Haiti': 'HTI',\n",
    "    'Yemen': 'YEM',\n",
    "    'South Sudan': 'SSD',\n",
    "    'Congo, DRC': 'COD',\n",
    "    'Ethiopia': 'ETH',\n",
    "    'Central African Republic': 'CAF',\n",
    "    'Djibouti': 'DJI',\n",
    "    'Pakistan': 'PAK',\n",
    "    'Mozambique': 'MOZ',\n",
    "    'Lebanon': 'LBN',\n",
    "    'Kenya': 'KEN',\n",
    "    'Guatemala': 'GTM',\n",
    "    'Sudan': 'SDN',\n",
    "    'Madagascar': 'MDG'\n",
    "}\n",
    "\n",
    "\n",
    "iso_codes_3_org = sorted([code for code in country_codes.values() if code is not None])\n",
    "\n",
    "# Now, to remove 'AFG', 'SSD', and 'ETH' from the list, you can do it with a loop or list comprehension:\n",
    "iso_codes_3 = [code for code in iso_codes_3_org if code not in ('AFG', 'SSD', 'ETH')]\n",
    "\n",
    "\n",
    "print(iso_codes_3_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5080bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Target Countries\n",
    "target_countries = {\n",
    "    'MWI': 'ADM3',\n",
    "    'ETH': 'ADM3',\n",
    "    'NGA': 'ADM2',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b84bf595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Target Countries\n",
    "target_countries = {\n",
    "    'AFG': 'ADM3',\n",
    "    'KEN': 'ADM3',\n",
    "    'HTI': 'ADM2',\n",
    "    'SSD': 'ADM2',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "932f36c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Read in chunks to apply row filter\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(home\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mstores\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mothers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWLD_RTFP_mkt_2024-01-25\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWLD_RTFP_mkt_2024-01-25.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Filter rows within each chunk\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     filtered_chunk \u001b[38;5;241m=\u001b[39m chunk[chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISO3\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(country_codes\u001b[38;5;241m.\u001b[39mvalues())]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Append filtered rows to list\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\master\\lib\\site-packages\\pandas\\io\\parsers.py:1171\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1170\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1171\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\.conda\\envs\\master\\lib\\site-packages\\pandas\\io\\parsers.py:1230\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[1;32m-> 1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\master\\lib\\site-packages\\pandas\\io\\parsers.py:1196\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1195\u001b[0m     nrows \u001b[38;5;241m=\u001b[39m _validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m-> 1196\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;66;03m# May alter columns / col_dict\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_index(ret)\n",
      "File \u001b[1;32m~\\.conda\\envs\\master\\lib\\site-packages\\pandas\\io\\parsers.py:2155\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2154\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2155\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2156\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   2157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:918\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:2042\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store filtered data\n",
    "filtered_data = []\n",
    "\n",
    "# Read in chunks to apply row filter\n",
    "for chunk in pd.read_csv(home+r'\\stores\\raw\\others\\WLD_RTFP_mkt_2024-01-25\\WLD_RTFP_mkt_2024-01-25.csv', chunksize=10000):\n",
    "    # Filter rows within each chunk\n",
    "    filtered_chunk = chunk[chunk['ISO3'].isin(country_codes.values())]\n",
    "    # Append filtered rows to list\n",
    "    filtered_data.append(filtered_chunk)\n",
    "\n",
    "# Concatenate all filtered chunks into a single DataFrame\n",
    "price_df = pd.concat(filtered_data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a43b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = price_df[price_df['mkt_name']!='Market Average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "779d696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df.to_csv('C:\\\\Users\\\\ck24\\\\OneDrive - University of Illinois - Urbana\\\\Documents\\\\FoodSecurityIPC\\\\stores\\\\price_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "371fbe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_home = 'C:\\\\Users\\\\ck24\\\\OneDrive - University of Illinois - Urbana\\\\Documents\\\\geospatial_data_collection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14584ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df.to_csv(geo_home+r'\\stores\\processed\\price_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1257ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df[price_df['country']=='South Sudan'].to_csv(geo_home+r'\\stores\\processed\\price_df_ssd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3daa1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
