# Module: Model Evaluation, Fairness & Explainable AI

---

## 1. Motivation
Building machine learning models is only half the job.  
We must also ask:
- **Is the model accurate?**
- **Is it fair?**
- **Can we explain its decisions?**

Without careful evaluation, ML systems risk being **biased, opaque, and untrustworthy**.  
This module teaches you how to evaluate performance, audit fairness, and improve interpretability.

---

## 2. Evaluation Metrics

### Classification Metrics
- **Accuracy**
\[
\text{Accuracy} = \frac{\text{# correct predictions}}{\text{total predictions}}
\]

- **Precision / Recall / F1**
\[
\text{Precision} = \frac{TP}{TP + FP}, \quad 
\text{Recall} = \frac{TP}{TP + FN}
\]
\[
F1 = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\]

- **ROC-AUC** for ranking quality.

### Regression Metrics
- **Mean Squared Error (MSE):**
\[
MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
\]

- **\( R^2 \) (Coefficient of Determination):**
\[
R^2 = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}
\]

---

## 3. Fairness in Machine Learning

### Bias Problem
Models can **systematically disadvantage groups** (e.g., gender, ethnicity).  
Fairness auditing checks if predictions differ across sensitive groups.

### Group Fairness Metrics
- **Demographic Parity Difference**
\[
P(\hat{y}=1 | A=0) - P(\hat{y}=1 | A=1)
\]

- **Equal Opportunity Difference**
\[
P(\hat{y}=1 | y=1, A=0) - P(\hat{y}=1 | y=1, A=1)
\]

where \( A \) is a sensitive attribute (e.g., sex, race).

We will use the **fairlearn** library to audit.

---

## 4. Explainability & Interpretability

### Why Explain Models?
- Trust: Stakeholders need to understand *why*.  
- Debugging: Detect spurious correlations.  
- Regulation: Some industries require explainability.

### Tools
- **Feature Importance** (global explanation).  
- **SHAP (SHapley Additive exPlanations)** â€” game-theoretic local explanations.  

SHAP values estimate how much each feature contributes to a specific prediction.  

---

## 5. Objectives
- Learn accuracy and performance metrics.  
- Audit bias with fairness metrics.  
- Use SHAP to explain black-box models.  

---

## 6. Expected Outcomes
By the end of this module, you will be able to:
- Evaluate classification/regression models with multiple metrics.  
- Audit fairness using group metrics.  
- Explain model predictions using feature importance and SHAP.  

---

## References
- [Scikit-learn Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)  
- [Fairlearn Documentation](https://fairlearn.org/main/)  
- [SHAP Documentation](https://shap.readthedocs.io/en/latest/)  
