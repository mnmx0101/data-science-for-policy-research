# Module: Natural Language Processing (NLP) with spaCy & Hugging Face Transformers

---

## 1. Motivation
Most of the worldâ€™s data is **text**: news articles, social media posts, research papers, emails.  
Natural Language Processing (NLP) helps machines **understand human language**, extract knowledge, and even generate coherent responses.

Real-world applications include:
- **Text extraction** (information retrieval, named entity recognition).
- **Thematic analysis** (clustering or topic modeling).
- **Sentiment analysis** (understanding opinions).

---

## 2. Conventional NLP vs Transformers

### 2.1 spaCy (Rule-based + Statistical NLP)
- Focus on efficiency and linguistic annotations.  
- Provides tokenization, POS tagging, named entity recognition (NER).  
- Good for structured extraction.

### 2.2 Hugging Face Transformers (Deep Learning)
- Based on **transformer architectures** (e.g., BERT, RoBERTa).  
- Use **attention mechanisms** to capture context.  
- Pre-trained on massive corpora, fine-tuned for tasks like sentiment classification.  

---

## 3. Core NLP Concepts

### Tokenization
Splitting text into words or subwords.
\[
\text{"ChatGPT is amazing"} \;\;\to\;\; ["Chat", "GPT", "is", "amazing"]
\]

### Word Vectors (Embeddings)
Words represented as high-dimensional vectors.  
Contextual embeddings (e.g., BERT) adjust meaning by context.

### Named Entity Recognition (NER)
Identifying entities in text.
\[
\text{"Barack Obama was born in Hawaii."} \;\;\to\;\; \{ \text{PERSON: Barack Obama}, \text{GPE: Hawaii} \}
\]

### Sentiment Analysis
Predicting positive/negative/neutral sentiment.  
\[
\text{"This movie is fantastic!"} \;\;\to\;\; Positive
\]

---

## 4. Objectives
- Use **spaCy** for tokenization, POS tagging, and entity recognition.  
- Use **transformers** for sentiment and theme analysis.  
- Compare conventional vs deep learning NLP methods.  

---

## 5. Expected Outcomes
You will be able to:
- Process raw text into structured tokens and entities.  
- Run sentiment analysis using pre-trained transformer models.  
- Extract themes from documents.  
- Understand trade-offs: speed vs accuracy, conventional vs deep learning.  

---

## 6. Useful References
- [spaCy Documentation](https://spacy.io/usage)  
- [Hugging Face Transformers](https://huggingface.co/transformers/)  
- [BERT Explained](https://jalammar.github.io/illustrated-bert/)  
